# 0. 구글드라이브 정의

구글 드라이브는 파일 저장 및 동기화 서비스로, 문서, 사진, 비디오, 기타 파일을 클라우드에 보관할 수 있도록 한다. 이 파일은 컴퓨터, 스마트폰 등 어떤 단말에서도 이용 가능해야 한다. 아울러 보관된 파일은 친구, 가족, 동료들과 손쉽게 공유할 수 있어야 한다.

# 1. 설계 범위

## 기능적 요구사항

- 파일 추가: 가장 쉬운 방법은 파일을 구글 드라이브 안으로 드래그 앤 드롭하는 것이다.
- 파일 다운로드
- 여러 단말에 파일 동기화: 한 단말에서 파일을 추가하면 다른 단말에도 자동으로 동기화되어야 한다.
- 파일 갱신 이력 조회(revision history)
- 파일 공유
- 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시

## 설계 범위에서 제외되는 기능

- 구글 문서(Google doc) 편집 및 협업 기능: 구글 문서는 여러 사용자가 같은 문서를 동시에 편집할 수 있도록 하는데, 이 부분은 설계 범위에서 제외한다.

## 비기능적 요구사항

- **안정성**: 저장소 시스템에서 안정성은 아주 중요하다. 데이터 손실은 발생하면 안 된다.
- **빠른 동기화 속도**: 파일 동기화에 시간이 너무 많이 걸리면 사용자는 인내심을 잃고 해당 제품을 더 이상 사용하지 않게 될 것이다.
- **네트워크 대역폭**: 이 제품이 네트워크 대역폭을 불필요하게 많이 소모하면 사용자는 좋아하지 않을 것이다. 모바일 데이터 플랜을 사용하는 경우라면 더욱 그렇다.
- **규모 확장성**: 이 시스템은 아주 많은 양의 트래픽도 처리 가능해야 한다.
- **높은 가용성**: 일부 서버에 장애가 발생하거나, 느려지거나, 네트워크 일부가 끊어져도 시스템은 계속 사용 가능해야 한다.

## 개략적 추정치

### 가정 사항

- 가입 사용자: 5천만 명 (50 million)
- DAU(일간 활성 사용자): 1천만 명
- 모든 사용자에게 10GB의 무료 저장공간 할당
- 매일 각 사용자가 평균 2개의 파일을 업로드한다고 가정
- 각 파일의 평균 크기: 500KB
- 읽기:쓰기 비율 = 1:1

### 추정치 계산

- **필요한 저장공간 총량** = 5천만 사용자 × 10GB = 500 페타바이트(Petabyte)
- **업로드 API QPS** = 1천만 사용자 × 2회 업로드 ÷ 24시간 ÷ 3600초 = 약 240
- **최대 QPS** = QPS × 2 = 480

# 2. 개략적 설계안 제시

## 초기 구성

이번에는 모든 것을 담은 한 대 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가는 단계를 밟아 보겠다.

우선 아래와 같은 구성의 서버 한 대로 시작해 보자.

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템.
    - 파일 저장을 위해 우선은 1TB 의 공간을 사용할 것이다.

1. 웹 서버를 설치하고, 관계형 데이터베이스를 깔고, 업로드되는 파일을 저장할 디렉터리를 준비한다.
2. 디렉터리 안에는 namespace라 불리는 하위 디렉터리들을 둔다.
3. 각 네임스페이스 안에는 특정 사용자가 올린 파일을 보관된다. 
    1. 이 파일들은 원래 파일과 같은 이름을 갖는다.
    2. 각 파일과 폴더는 그 상대 경로를 네임스페이스 이름과 결합하면 유일하게 식별해 낼 수 있다.

<img width="882" height="272" alt="image" src="https://github.com/user-attachments/assets/1f26b526-f60c-412c-84b4-9ade304a2d6d" />


## API

이 서비스는 기본적으로 세 가지 API가 필요하다.

### 1. 파일 업로드 API

이 시스템은 두 가지 종류의 업로드를 지원한다.

**업로드 타입:**

- **단순 업로드**: 파일 크기가 작을 때 사용
- **이어 올리기 (resumable upload)**: 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높을 때 사용

**이어 올리기 API:**

- **URL**: https://api.example.com/files/upload?uploadType=resumable
- **인자**:
    - `uploadType=resumable`
        - 단순 업로드의 경우에는 `uploadType=media`
    - `data`: 업로드할 로컬 파일

**이어 올리기 절차 (3단계):**

1. 이어 올리기 URL을 받기 위한 최초 요청 전송
2. 데이터를 업로드하고 업로드 상태 모니터링
3. 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작

### 2. 파일 다운로드 API

- **URL**: https://api.example.com/files/download
- **인자**:
    - `path`: 다운로드할 파일의 경로

**예시:**

```json
{
  "path": "/recipes/soup/best_soup.txt"
}
```

### 3. 파일 업데이트 히스토리 API

- **URL**: https://api.example.com/files/list_revisions
- **인자**:
    - `path`: 갱신 히스토리를 가져올 파일의 경로
    - `limit`: 히스토리 길이의 최대치

**예시:**

```json
{
  "path": "/recipes/soup/best_soup.txt",
  "limit": 20
}
```

## 한 대 서버의 제약

업로드되는 파일이 많아지다 보면 결국에는 파일 시스템은 가득 차게 된다.

이렇게 되면 사용자는 더 이상 파일을 올릴 수 없게 되므로, 문제를 해결해야 한다. 가장 대표적인 해결책은 데이터를 샤딩(sharding)하여 여러 서버에 나누어 저장하는 것이다. 샤딩 키는 유저 아이디 등을 사용할 수 있을 것이다.

한 대 서버만 운영중인 상황이라면, 서버의 장애가 매우 치명적이다. 위의 설계안에서 서버에 장애가 생기면 모든 데이터를 잃게된다. 이 문제에 대한 해결책으로 S3와 같은 객체 스토리지 서비스를 도입할 수 있다. S3는 다중화를 지원하는데, 같은 지역(리전) 안에서 다중화를 할 수도 있고 여러 지역(리전)에 걸쳐 다중화를 할 수도 있다.

<img width="848" height="305" alt="image" src="https://github.com/user-attachments/assets/bb94ecee-2e95-4f2c-b40d-dec478213d73" />


그리고 장애에 대응하기 위해 다음과 같은 방법도 도입할 수 있겠다.

1. 로드밸런서 : 네트워크 트래픽을 분산하기 위해 로드밸런서를 사용한다. 로드밸런서는 트래픽을 고르게 분산할 수 있을 뿐 아니라, 특정 웹 서버에 장애가 발생하면 자동으로 해당 서버를 우회해준다.
    
    ```java
    # 가중치 기반 분산
    upstream backend {
        server 192.168.1.10:8080 weight=3;  # 더 많은 트래픽
        server 192.168.1.11:8080 weight=2;  # 평균적인 트래픽
        server 192.168.1.12:8080 weight=1;  # 더 적은 트래픽
    }
    
    # 또는 실패횟수 기반
    upstream backend {
        server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
        server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;
        server 192.168.1.12:8080 backup;  # 백업 서버(위에 모두 실패했을 때만)
    }
    
    # 혹은 합치기
    upstream backend {
        server 192.168.1.10:8080 weight=3 max_fails=3 fail_timeout=30s;
        server 192.168.1.11:8080 weight=2 max_fails=3 fail_timeout=30s;
        server 192.168.1.12:8080 weight=1 max_fails=3 fail_timeout=30s;
        server 192.168.1.13:8080 backup;  # 백업 서버
    }
    ```
    
2. 웹 서버 : 로드밸런서를 추가하고 나면 더 많은 웹 서버를 추가할 수 있다. 트래픽에 유연하게 수평확장이 가능해진다.
3. 메타데이터 데이터베이스 : 데이터베이스를 파일 저장 서버에서 분리하여 SPOF를 회피한다.
    1. 파티셔닝을 해두면 데이터의 안전성과 접근속도가 올라갈 수 있을 것이다.
4. 파일 저장소: 객체 스토리지를 사용하면 확장성을 높일 수 있다.
    1. 객체 스토리지를 사용하면 다중화가 쉬워지는 장점도 있다.

## 동기화 충돌

구글 드라이브 같은 대형 저장소 시스템의 경우 때때로 동기화 충돌이 발생할 수 있다. 두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트하려고 하는 경우다.

<img width="890" height="240" alt="image" src="https://github.com/user-attachments/assets/8f20e2dc-0f9f-42a8-b1eb-6f011dd8e9cd" />


오류가 발생한 시점에 이 시스템에는 같은 파일의 두 가지 버전이 존재하게 된다. 사용자 2가 가지고 있는 로컬 사본과 서버에 있는 사용자 1이 제출한 동기화된 최신 버전이 그것이다. 


# 2. 개략적 설계안

아래 그림은 이번 문제에 대한 개략적 설계안이다.

<img width="916" height="665" alt="image" src="https://github.com/user-attachments/assets/d16ee263-5853-4ce4-8b14-505a53872c5e" />


컴포넌트별 역할은 다음과 같다.

- 블록 저장소 서버: 파일 블록을 클라우드 저장소에 업로드하는 서버다. 파일을 여러개의 블록(객체)으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당된다.
- 클라우드 저장소: 파일은 블록 단위로 나눠져 클라우드 저장소에 보관된다.
- cold storage: 오랫동안 사용되지 않은 비활성 데이터를 저장하기 위한 컴퓨터 시스템이다.
- 로드밸런서: 요청을 모든 API 서버에 고르게 분산한다.
- API 서버 : 파일 업로드 외에 거의 모든 것을 담당하는 서버다. 사용자 정보, 메타데이터 갱신 등에 사용한다.
- 메타데이터 데이터베이스: 여러 메타데이터 정보 및 사용자 데이터를 관리한다. 실제 파일은 클라우드에 보관하며, 이 데이터베이스에는 오직 메타 데이터만 둔다.
- 메타데이터 캐시 : 성능을 높이기 위해 자주 쓰이는 메타데이터는 캐시한다.
- 알림 서비스: 특정 이벤트가 발생했음을 클라이언트에게 알리는데 쓰이는 PUB/SUB 기반 시스템이다.
- 알림 서비스 큐: 잠시 오프라인 상태가 된 사용자에게 전달된 알림을 일시적으로 보관했다가, 연결이 재개됐을 때 전달하기 위한 큐이다.

# 3. 상세 설계

각 컴포넌트나 기능 수행 절차에 대해 자세히 알아보자.

## 블록 저장소 서버

정기적으로 갱신되는 큰 파일들은 업데이트가 일어날 때마다 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 잡아먹게 된다. 이를 위한 최적화는 다음과 같은 것들이 있다.

1. 델타 동기화 (dela sync): 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화하는 것이다.
2. 압축(compression): 블록 단위로 압축해 두면 데이터 크기를 많이 줄일 수 있다. 이때 압축 알고리즘은 파일 유형에 따라 정하는 것이 좋다.

이 시스템에서 블록 저장소 서버는 파일 업로드에 관계된 힘든 일을 처리하는 컴포넌트다.

### 블록 저장소 서버 주요 역할

- 클라이언트가 보낸 파일을 블록 단위로 나눠야 함
- 각 블록에 압축 알고리즘을 적용해야 함
- 암호화까지 해야 함
- 전체 파일을 저장소 시스템으로 보내는 대신 **수정된 블록만 전송**해야 함
    
    <img width="868" height="400" alt="image" src="https://github.com/user-attachments/assets/612736dd-2faa-4698-ad4c-cbaf02ebf9cc" />

    

### 블록 저장소 서버 처리 과정

1. **주어진 파일을 작은 블록들로 분할한다**
2. **각 블록을 압축한다**
3. **클라우드 저장소로 보내기 전에 암호화한다**
4. **클라우드 저장소로 보낸다**

## 높은 일관성 요구사항

이 시스템은 강한 일관성 모델을 기본으로 지원해야 한다. 같은 파일이 단말이나 사용자에 따라 다르게 보이는 것은 허용할 수 없다는 뜻이다. 메타데이터 캐시와 DB 계층도 같은 원칙이 적용되어야 한다.

메모리 캐시가 강한 일관성을 달성하려면 다음 사항을 보장해야 한다.

1. 캐시에 보관된 사본과 데이터베이스에 있는 원본이 항상 일치한다.
2. 데이터베이스에 보관된 원본에 변경이 발생하면 항상 캐시에 있는 사본을 무효화한다.

키-값 스토어 같은 NoSQL DB는 트랜잭션이 별도로 없으므로, 강한 일관성을 달성하기 위해서는 동기화 로직을 직접 추가해야 한다.

## 메타데이터 데이터베이스

이 데이터베이스의 스키마 설계안이다. 중요한 것만 간추린 아주 단순화된 형태의 스키마임에 유의하자.

<img width="904" height="649" alt="image" src="https://github.com/user-attachments/assets/b0c37bcf-1301-482b-bcb7-8ab533f0229f" />


## 업로드 절차

사용자가 파일을 업로드하면 무슨 일이 벌어지는 아래에 시퀀스 다이어그램을 통해 알아보자.

<img width="903" height="516" alt="image" src="https://github.com/user-attachments/assets/87dd9079-c985-4f21-8b04-f2cf56637415" />


1. 파일 메타데이터 추가 요청을 API서버로 보내고, 
2. 블록 저장소 서버로 추가하고자 하는 파일을 전송해야 한다.

## 다운로드 절차

파일 다운로드는 파일이 새로 추가되거나 편집되면 자동으로 시작된다. 그렇다면 클라이언트는 다른 클라이언트가 파일을 편집하거나 추가했다는 사실을 어떻게 감지하는 것일까?

<img width="869" height="502" alt="image" src="https://github.com/user-attachments/assets/d0075bf3-ba26-4a7a-93e2-bf96ee73ae1b" />


1. 클라이언트 A 가 접속 중이고 다른 클라이언트가 파일을 변경하면 알림 서비스가 클라이언트 A 에게 변경이 발생했으니 새 버전을 끌어가야 한다고알린다.
2. 클라이언트 A 가 네트워크에 연결된 상태가 아닐 경우는 데이터는 캐시에 보관될 것이다. 해당 클라이언트의 상태가 접속 중으로 바뀌면 그때 해당 클라이언트는 새 버전을 가져갈 것이다
3. 알림을 받은 클라이언트는 API 서버로 메타데이터를 요청하고, 클라우드 저장소에 메타데이터를 토대로 블록 요청을 할 것이다.

## 알림 서비스

파일의 일관성을 유지하기 위해 클라이언트는 로컬에서 파일이 수정되었음을 감지하는 순간 다른 클라이언트에 그 사실을 알려서 충돌 가능성을 줄여야 한다. 알림 서비스는 그 목적으로 이용된다.

알림 서비스는 이벤트 데이터를 클라이언트들로 보내는 서비스다. 따라서 다음 두 가지 정도의 선택지가 있다.

1. 롱 폴링: 드롭박스가 이 방식을 채택하고 있다.
2. 웹소켓: 클라이언트와 서버 사이에 지속적인 통신 채널을 제공한다.

여기서는 롱 폴링을 사용할 것이다. 왜냐하면, 채팅서비스와 달리 양방향 통신이 필요하지는 않다. 서버 → 클라이언트로 변경이 있음을 알려줘야 할 뿐이다.

따라서 연결을 계속해서 유지해야 하는 소켓보다 비교적 가벼운 롱 폴링이 더 적합해 보인다.

## 저장소 공간 절약

파일 갱신 이력을 보존하고 안정성을 보장하기 위해서는 파일의 여러 버전을 여러 데이터센터에 보관할 필요가 있다. 그런 상황에서 모든 버전을 자주 백업하게 되면 저장용량이 너무 빨리 소진될 가능성이 있다. 이런 문제를 피하고 비용을 절감하기 위해서는 보통 아래 세 가지 방법을 사용한다.

1. 중복 제거: 중복된 파일 블록을 계정 차원에서 제거하는 방법이다. 두 블록이 같은 블록인지는 해시 값을 비교하여 판단한다.
2. 지능적인 저장 전략을 도입한다.
    1. 한도 설정 : 보관해야 하는 파일 버전 개수에 상한을 두는 것이다. 상한에 도달하면 제일 오래된 버전은 버린다.
    2. 중요한 버전만 보관 : 어떤 파일은 아주 자주 바뀐다. 예를 들어 편집 중인문서가 업데이트될 때마다 새로운 버전으로 관리한다면 짧은 시간 동안 엄청난 사본이 만들어 질 수도 있다.
3. 자주 쓰이지 않는 데이터는 아카이빙 저장소(cold storage)로 옮긴다. 아마존 S3 글래시어(glacier)같은 아카이빙 저장소 이용료는 S3 보다 훨씬 저렴하다

## 장애 처리

주요한 장애로는 다음과 같은 것들이 있을 수 있다.

1. 로드 밸런서 장애: 로드밸런서에 장애가 발생할 경우 세컨더리 로드밸런서가 활성화되어 트래픽을 이어받아야 한다. 로드 밸런서끼리는 보통 heartbeat 신호를 주기적으로 보내서 상태를 모니터링한다.
2. 클라우드 저장소 장애: 이 장애에 대응하기 위해서 객체 스토리지 버킷을 여러 지역에 다중화 시킨다.
3. API 서버 장애: 로드밸런서가 장애 서버를 격리하도록 해야한다.
4. 메타데이터 캐시 장애: 메타데이터 캐시 서버도 다중화하여 안정성을 높일 수 있다.
5. 메타데이터 DB 장애: 마찬가지로 다중화하여 안정성을 높여놓아야 한다.
6. 알림 서비스 장애: 사용자와의 롱폴링 연결을 관리해야 하는 역할을 수행하기 때문에, 알림 서비스 서버에 장애가 생기면 엄청난 수의 사용자가 연결 지연이 생길 것이다.
7. 사용자 백업 큐 장애: 큐 또한 다중화시킬 수 있다.

# 4. 마무리

설계안에 다른 선택지가 있었는 지 논의해보면 좋을 것이다.

1. 블록 저장소 서버를 거치지 않고, 파일을 직접 클라우드 저장소에 업로드하면?
    1. 업로드 시간이 빨라진다.
    2. 그러나 저장공간이 훨씬 많이 필요할 것이다.
    3. 분할, 압축, 암호화 로직을 모두 클라이언트에 두어야 한다. ⇒ 이것은 매우 적절치 못하다.
2. 롱폴링 대신 웹소켓을 사용했을 때의 장점은?
    1. 단점이 충분히 커서 무조건 롱폴링이 더 나은 것인지…

---

# 추가학습

## 동기화 충돌 해결 전략

이러한 동기화 문제를 해결하기 위해 구글 드라이브는 **3단계 해결 전략**을 사용한다:

### 1. 자동 해결 (Auto-merge)

시스템이 자동으로 처리할 수 있는 단순한 충돌들:

- **파일 이동/이름 변경**: 타임스탬프 기반으로 최신 변경사항 적용
- **메타데이터 변경**: 파일 설명, 태그 등은 병합하거나 최신 값 적용
- **폴더 구조 변경**: 데이터 손실을 방지하는 안전한 방향으로 자동 선택
- **권한 설정 변경**: 보안을 위해 더 제한적인 권한으로 자동 적용

### 2. 충돌 파일 생성 (Conflict Copy Creation)

자동 해결이 불가능한 **파일 내용 변경** 시 사용하는 방식:

- **동작 원리**: 서버의 최신 버전은 원본으로 유지하고, 충돌된 로컬 버전은 별도 파일로 저장
- **파일명 예시**:
    - 원본: `document.txt`
    - 충돌 파일: `document (사용자2의 충돌된 사본 2024-03-15).txt`
- **장점**: 완전한 데이터 보존, 사용자가 수동 병합 가능
- **단점**: 사용자 개입 필요, 저장 공간 증가

### 3. 사용자 개입 (User Choice)

매우 복잡한 충돌 상황에서 사용자에게 직접 선택권 제공:

- 어떤 버전을 유지할지 직접 선택
- 수동으로 두 버전을 비교하고 병합
- 향후 동일한 상황에 적용할 해결 규칙 설정

### 충돌 감지 기법 - 버전 벡터 (Version Vector)

각 클라이언트별로 버전 번호를 관리하여 정확한 충돌 감지:

```json
{
  "file_id": "document.txt",
  "version_vector": {
    "user1": 3,
    "user2": 2
  }
}
```
