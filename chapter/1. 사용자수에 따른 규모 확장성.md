# 단일서버
아래는 기본적이고 간단한 단일서버의 사용자 요청 처리 흐름이다.

<img width="400" height="245" alt="image" src="https://github.com/user-attachments/assets/8e2636ed-1017-43cc-91a1-becc022bf651" />

1. 사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속한다. **이 접속을 위해서는 도메인 이름을 도메인 이름 서비스 (Domain Name Service, DNS) 에 질의하여 IP 주소로 변환하는 과정이 필요하다. 여기서** DNS 는 보통 서드 파티 서비스를 이용하게 되므로, 우리 시스템의 일부는 아니다.
2. DNS 조회 결과로 IP 주소가 반환된다. 여기 예제에서는 그 주소가15.125.23.214이다. 이 주소는 그림에 나온 웹 서버의 주소이다.
3. 해당 IP 주소로 HTTP(HyperText Transter Protocol) 요청이 전달된다.
4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.

# 데이터베이스

웹 / 모바일 트래픽 처리 서버 ( 웹 계층 ) 와 데이터베이스 서버( 데이터 계층 )를 분리하면 그 각각을 독립적으로 확장해 나갈 수 있게 된다.

<img width="400" height="240" alt="image" src="https://github.com/user-attachments/assets/68ceae3c-7e8e-4bab-9de9-2a4fc8159277" />


### 데이터베이스의 선택

데이터베이스는 보통 전통적인 관계형 데이터베이스(relational database)와 비- 관계형 데이터베이스 사이에서 고를 수 있다. 관계형 데이터베이스는 관계형 데이터베이스 관리 시스템 (Relational Data-base Management System, RDBMS) 이라고도 부른다. RDBMS 가운데 가장 유명한 것으로는 MySQL, Oracle, PostgreSQL 등이 있다.

**관계형 데이터베이스는 자료를 테이블과 열, 칼럼으로 표현한다. SQL 을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인 (join) 하여 합칠 수 있다.**

비 관계형 데이터베이스는 **NoSQL(Not only SQL)**이라고도 부른다. 대표적인 것으로는 CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB 등이 있다.

NoSQL은 다시 네 부류로 나눌 수 있는데, **키- 값 저장소 (key-value store)**, **그래프 저장소 (graph store)**, **칼럼 저장소 (column store)**, 그리고 **문서 저장소 (document store)**가 그것이다. **이런 비관계형 데이터베이스는 일반적으로 조인 연산은 지원하지 않는다.**

RDB를 사용할지, 혹은 비 관계형 DB를 시용할 지는 어떻게 결정하는 것이 좋을까? 
아래와 같은 경우에는 비- 관계형 데이터베이스가 바람직한선택일 수 있다.

1. **아주 낮은 응답 지연시간(latency)이 요구됨**
2. **다루는 데이터가 비정형(unstructured) 이라 관계형 데이터가 아님**
3. 데이터 (ISON, YAML, XML 등 ) 를 직렬화하거나 (serialize) 역직렬화 (deserialize) 할 수 있기만 하면 됨
4. **아주 많은 양의 데이터를 저장할 필요가 있음**

또한, 관계형 DB는 읽기 연산에 특화되어 있어 효율적이지만, 쓰기 연산은 비효율적일 수 있다는 점도 감안하자.

# 수직적 규모 확장 vs 수평적 규모 확장

**'스케일 업 (scale up)'** 이라고도 하는 **수직적 규모 확장(vertical sealing)** 프로세스는 고정된 서버에 고사양 자원( 더 좋은 CPU, 더 많은 RAM 등 )을 추가하는 행위를 말한다.

반면 **'스케일 아웃 (scale out)'** 이라고도 하는 **수평적 규모 확장** 프로세스는 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.

서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택이며 , 이 방법의 가장 큰 장점은 단순함이다. 그러나 불행하게도 이 방법에는 몇 가지 심각한 단점이 있다.

1. **수직적 규모 확장에는 한계가 있다.** 한 대의 서버에 CPU 나 메모리를 무한대로 증설할 방법은 없다.
2. 수직적 규모 확장법은 **장애에 대한 자동복구(failover) 방안이나 다중화 방안을 제시하지 않는다.** 서버에 장애가 발생하면 서비스는 완전히 중단된다.

따라서 대규모 시스템에는 수평적 규모 확장법이 보다 적절하다. 앞서 본 단일 서버 설계에서는 단일 서버가 다운되면 사용자는 서비스를 전혀 이용하지 못한다. 또한, 서버의 부하가 올라가면 응답 속도가 느려질 수밖에 없다.

## 로드밸런서

**로드밸런서는 부하 분산 집합 (load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.**
로드밸런서로 주로 사용되는 Nginx 등의 프록시 서버는 부하 분산 이외에도 처리율 제한, SSL을 통한 암호화된 통신 처리, 정적 파일 서빙 등의 추가적인 역할을 수행할 수 있다. 

<img width="450" height="330" alt="image" src="https://github.com/user-attachments/assets/47c4cde3-e1f9-4262-aa20-5df92322e416" />


그림 1-4 와 같이, 사용자는 로드밸런서의 공개 IP 주소(public IP)로 접속한다. 따라서 **웹 서버는 클라이언트의 접속을 직접 처리하지 않는다. 더 나은 보안을 위해 서버 간 통신에는 사설(private) IP 주소가 이용된다.** 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에만 쓰일 수 있는 IP 주소로, 인터넷을 통해서는 접속할 수 없다.

그림 1-4 에 나온 대로, **부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면 장애를 자동복구하지 못하는 문제 (no failover)는 해소되며 , 웹 계층의 가용성(availability)은 향상된다.** 그 과정은 구체적으로 다음과 같다.

- 서버1 이 다운되면 모든 트래픽은 서버2 로 전송되게 한다. 따라서 웹 사이트 전체가 다운되는 일이 방지된다. 부하를 더 나누기 위해 새로운 서버를 추가할 수도 있다.
- 웹사이트로 유입되는 트래픽이 가파르게 증가하면 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오는데, 로드밸런서가 있으므로 우아하게 대처할 수 있다. 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다. 그러면 로드밸런스가 트래픽을 분산할 수 있다.

# 데이터베이스 다중화

데이터베이스의 장애 복구나 다중화를 지원하기 위해서는 데이터베이스 다중화를 이용할 수 있다.

많은 데이터베이스 관리 시스템이 다중화를 지원한다. **보통은 서버 사이에 Master -Slave 관계를 설정하고 데이터 원본은 Master 서버, 사본은 Slave 서버에 저장한다.**

쓰기 연산(insert, delete, update)은 마스터에서만 지원한다. 부 데이터베이스는 주 데이터베이스로부터 그 사본을 전달받으며, 읽기 연산(read)만을 지원한다.

<img width="600" height="570" alt="image" src="https://github.com/user-attachments/assets/1248717f-1d2d-4476-9e03-b9cf745c1791" />

대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높다. 따라서 그림과같이, 보통 부 데이터베이스의 수가 훨씬 많다.

## 데이터베이스 다중화의 이점

1. **더 나은 성능** : 다중화 모델에서 모든 데이터 변경 연산은 주 데이터베이스 서버로만 전달되는 반면, 읽기 연산은 부 데이터베이스 서버들로 분산된다. 병렬로 처리될 수 있는 질의 (query) 의 수가 늘어나므로, 성능이 좋아진다.
2. **안정성(reliability)** : 자연 재해 등의 이유로 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존될 것이다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있기 때문이다.
3. **가용성(availability)** : 데이터를 여러 지역에 복제해 둠으로써 , 하나의 데이터
베이스 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있게 된다.

## 다중화된 서버 중 하나가 다운된다면

데이터베이스를 다중화한 상황에서 서버 가운데 하나가 다운되면 어떤 일이 벌어질까?

1. 부 서버가 한 대 뿐인데 다운된 경우라면, 읽기 연산은 한시적으로 모두 주 데이터베이스로 전달될 것이다. 또한 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체할 것이다. 부 서버가 여러 대인 경우에 읽기 연산은 나머지 부 데이터베이스 서버들로 분산될 것이며, 새로운 부 데이터베이스 서버가 추가되어 장애 서버를 대체할 것이다.
2. 주 데이터베이스 서버가 다운되면 , 한 대의 부 데이터베이스만 있는 경우 해당 부 데이터베이스 서버가 새로운 주 서버가 될 것이며, 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행될 것이다. 그리고 곧 새로운 부 서버가 추가될 것이다.

그러나 부 서버에 보관된 데이터는 최신 상태가 아닐 수 있다. 이런 상황이라면, 복구 스크립트를 통해 부 서버에 없는 데이터를 추가해야만 한다.

## 새로운 설계안

다음 그림은 로드밸런서와 데이터베이스 다중화를 고려한 새로운 설계안이다.

<img width="600" height="560" alt="image" src="https://github.com/user-attachments/assets/c4b09d2a-5157-45be-a428-6781d4070893" />

1. 사용자는 DNS 로부터 로드밸런서의 공개 IP 주소를 받는다.
2. 사용자는 해당 IP 주소를 사용해 로드밸런서에 접속한다.
3. HTTP 요청은 서버-1 이나 서버-2 로 전달된다.
4. 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽는다.
5. 웹 서버는 데이터 변경 연산은 주 데이터베이스로 전달한다. 데이터 추가, 삭제, 갱신 연산 등이 이에 해당한다.

이제 응답시간을 개선해보자. 응답시간을 개선하기 위해서 보통 캐시를 붙이고, 정적 콘텐츠들을 CDN으로 옮기는 작업을 수행할 수 있다.

# 캐시

캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고 , 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다. 어플리케이션의 성능은 데이터를 얼마나 어떻게 가져오느냐에 따라 크게 좌우되는데, 캐시는 이를 완화할 수 있는 방안이다.

## 캐시 계층

**캐시 계층(Cache tier)은** 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다. 별도의 캐시 계층을 두면 성능이 개선될 뿐 아니라 데이터베이스의 부하를 줄일 수 있고 , 캐시 계층의 규모를 독립적으로 확장시키는 것도 가능해진다.

<img width="560" height="165" alt="image" src="https://github.com/user-attachments/assets/1f4e66a0-144e-4b39-9338-03514eabaf58" />

요청을 받은 웹 서버는 캐시에 응답이 저장되어 있는지를 본다. **만일 저장되어 있다면 해당 데이터를 클라이언트에 반환한다. 없는 경우에는 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 뒤 클라이언트에 반환한다.** 이러한 캐시 전략을 **주도형 캐시 전략**이라고 부른다.

캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API 를 제공한다. 따라서 웹서버와 연동하는 것도 간단하다.

## 캐시 사용 고려사항

캐시를 사용할 때는 아래 사항들을 고려하여야 한다.

1. 캐시는 어떤 상황에 바람직한가? 데이터 쓰기 작업보다 읽기 작업이 많을 때 유용하다.
2. 어떤 데이터를 캐시에 두어야 하는가 ? 캐시는 데이터를 휘발성 메모리에 두므로 , 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.
3. 캐시에 보관된 데이터는 어떻게 만료 (expire) 되는가 ? 이에 대한 정책을 마련해 두는 것이 좋다. 만료시간은 너무 길지도, 짧지도 않은 것이 적합하다.
4. 데이터 저장소의 원본과 캐시 내의 사본간의 일관성은 어떻게 유지되는가? 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 된다.
5. 장애에는 어떻게 대처할 것인가 ? 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점 (Single Point of Failure, SPOF) 이 되어버릴 가능성이 있다.

> [!NOTE]
> **단일 장애 지점(SPOF) 이란?**
> 
> 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우, 우리는 해당 지점을 **단일 장애 지점**이라고 부른다. 이러한 SPOF를 피하기 위해서는 장애 지점을 최대한 분산시켜야 한다.

1. 캐시 메모리는 얼마나 크게 잡을 것인가 ? 캐시 메모리가 너무 작으면 데이터가 너무 자주 캐시에서 밀려나버려(eviction) 캐시의 성능이 떨어지게 된다.
2. 데이터 방출 (eviction) 정책은 무엇인가 ? 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다. 자주 사용되는 방출 정책은 LRU이며, 추가적으로 LFU나 FIFO 등이 있다.

# CDN(콘텐츠 전송 네트워크)

CDN 은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 주로 이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 때 사용한다. 어떤 사용자가 웹사이트를 방문하면 **사용자에게서 물리적으로 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다.**

<img width="400" height="142" alt="image" src="https://github.com/user-attachments/assets/5f48bf29-84c1-4048-aa2b-79dcb4218134" />


## CDN 사용 고려사항

1. **비용 :** CDN 은 보통 제 3 사업자 (third-pary providers) 에 의해 운영되며, CDN 으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내게 된다.
2. **적절한 만료 시한 설정** : 시의성이 중요한(time-sensitive) 콘텐츠의 경우 만료 시점을 잘 정해야 한다. 너무 길면 콘텐츠의 신선도가 떨어질 것이고, 너무 짧으면 원본 서버에 빈번히 접속하게 되어서 좋지 않다.
3. **CDN 장애에 대한 대처 방안** : CDN 자체가 죽었을 경우 웹사이트 / 애플리케이션이 어떻게 동작해야 하는지 고려해야 한다.
4. **콘텐츠 무효화(invalidation) 방법** : 아직 만료되지 않은 콘텐츠라 하더라도 아래 방법 가운데 하나를 쓰면 CDN 에서 의도적으로 제거할 수 있다.
    1. CDN 서비스 사업자가 제공하는 **API 를 이용한 콘텐츠 무효화**
    2. 콘텐츠의 다른 버전을 서비스하도록 **오브젝트 버저닝(object versioning)**

## 확장된 설계

<img width="450" height="440" alt="image" src="https://github.com/user-attachments/assets/a38ca196-d502-4b13-9e13-a848680d3845" />

변화된 부분은 다음과 같다.

1. 정적 콘텐츠 (JS, CSS, 이미지 등 ) 는 더 이상 웹 서버를 통해 직접 서비스하지 않으며, 물라적으로 가까운 CDN 을 통해 제공하여 더 나은 성능을 보장한다.
2. 캐시가 데이터베이스의 부하를 줄여준다.

# 무상태(Stateless) 웹 계층

웹 계층을 수평적으로 확장하기 위해서는 상태 정보 ( 사용자 세션 데이터와 같은 ) 를 웹 계층에서 제거하여야 한다. 바람직한 전략은 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고 , 필요할 때 가져오도록 하는 것이다. 이렇게 구성된 웹 계층을 "**무상태 웹 계층"**이라 부른다.

## Stateful 아키텍처

상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지하여요청들 사이에 공유되도록 한다. 이 상태는 사용자 정보에 대한 세션이나, 웹서버에서 관리하는 자료구조 등이 있다.

사용자 A에 대한 인증 정보를 담은 세션을 서버 A에서 관리한다면, 사용자 A를 인증하기 위한 HTTP 요청은 반드시 서버 A로 전달되어야 한다. 같은 클라이언트의 요청은 항상 같은 서버로 전송되어야 한다고 할 수 있다. 대부분의 로드 밸런서는 이를 지원하기 위해 **Sticky Session**이라는 기능을 제공하지만, 이는 로드 밸런서에게 부담을 가중한다. 또한 웹서버의 추가 또는 제거 작업이 더 까다로워진다.

## Stateless 아키텍처

<img width="420" height="327" alt="image" src="https://github.com/user-attachments/assets/ebf4b0d8-bb2f-4b68-a9a8-a586985dea62" />


이 구조에서 사용자로부터의 HTTP 요청은 어떤 웹 서버로도 전달될 수 있다. 웹 서버는 상태 정보가 필요할 경우 공유 저장소(shared storage)로부터 데이터를 가져온다. 따라서 **상태 정보는 웹 서버로부터 물리적으로 분리되어 있다.**

## 변경된 설계

<img width="450" height="430" alt="image" src="https://github.com/user-attachments/assets/a73328c1-f1ba-4117-8ac1-6f896569a889" />


세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장하도록 만들었다. 이 공유 저장소는 관계형 데이터베이스일 수도있고, Memcached/Redis같은 캐시 시스템일 수도 있으며, 그림처럼 NoSQL 일 수도 있다.

1번의 자동 규모 확장(Auto-Scaling)은 매트릭에 설정된 트래픽 양에 대한 옵션에 따라 웹 서버를 자동으로 추가하거나 삭제하는 기능을 뜻한다. 상태 정보가 웹 서버에서 제거되었으므로, 트래픽 양에 따라 확장 혹은 축소가 용이한 구조가 되었다.

# 데이터 센터

서비스의 가용성을 높이고 전 세계 어디서도 사용할 수 있도록 하기 위해서는 여러 데이터 센터(Data center)를 지원하는 것이 필수다. 

아래의 그림 1-15 는 두 개의 데이터 센터를 이용하는 사례다. 장애가 없는 상황에서 사용자는 두 데이터 센터 중 가장 가까운 데이터 센터로 안내되는데 , 통상 **이 절차를 지리적 라우팅(geoDNS-routing 또는 geo-routing)**이라고 부른다.

> [!TIP]
> **geoDNS 란?**
> 
> geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해 주는 DNS 서비스다.

<img width="380" height="360" alt="image" src="https://github.com/user-attachments/assets/8217fa25-4332-4231-9ec0-35bb90a2c8c5" /> <img width="380" height="362" alt="image" src="https://github.com/user-attachments/assets/ec42494b-f7b9-4d3f-98fa-540854de3ef8" />


이들 데이터 센터 중 하나에 심각한 장애가 발생하면 장애가 발생한 데이터 센터로 향하던 모든 트래픽은 다음으로 가까운 장애가 없는 데이터 센터로 전송된다.

위와 같은 다중 데이터센터 아키텍처를 만들려면 몇 가지 기술적 난제를해결해야 한다.

1. **트래픽 우회** : 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 한다. geoDNS 는 사용자에게서 가장 가까운 데이터센터로 트래픽을 보낼 수 있도록 도와주는 기능도 제공한다.
2. **데이터 동기화(data synchronization)**: 데이터 센터마다 별도의 데이터베이스 를 사용하고 있는 상황이라면, 트래픽이 향하는 해당 데이터센터에는 찾는 데이터가 없거나 최신이 아닐 수 있다. **이런 상황을 막는 보편적 전략은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다.**
3. 테스트와 배포 : 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보는 것이 중요하다. 자동화된 배포 도구(CICD)가 여기에 도움을 줄 수 있다.

# 메세지큐

시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 독립적으로 확장될 수 있도록 하여야 한다. 메시지 큐(message queue)는 많은 실제 분산 시스템이 이 문제를 풀기 위해 채택한 핵심 전략이다.

메시지 큐는 **메시지의 무손실**(durability, 즉 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하며, 비동기 통신(asynchronous communication)을 지원하는 컴포넌트다.

**메시지의 버퍼 역할**을 하며, **비동기적**으로 전송한다.

> [!NOTE]
> **메세지큐의 비동기 통신**
> 
> 발송자와 수신자가 서로를 기다리지 않고 각자의 속도로 독립적으로 메시지를 주고받을 수 있는 방식이라는 의미.

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서,  서비스의 확장이 용이해진다. 메세지 큐의 수신자 역할을 하는 서버와 발신자 역할을 하는 **서버 간의 결합도가 감소**되고, 컴포넌트 별 확장이 용이해진다.

생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고 , 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있다.

# 로그 , 메트릭 그리고 자동화

서비스와 함께 사업 규모가 커지고 나면 로그나 매트릭, 자동화 같은 도구에 필수적으로 투자해야 한다.

- 로그 : 에러 로그 등을 모니터링하는 것은 중요하다. 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 하기 때문이다. 로그를 단일 서비스로 모아서 처리하기 위해서 **ELK스택** 등을 활용할 수 있다.

> [!TIP]
> **ELK(ELK 스택)은**
> 
> Elasticsearch + Logstash + Kibana 3가지 서비스를 조합한 로그 관리 및 분석 기술스택
> 
> - **Logstash** - 로그 수집, 파싱, 변환, 전송
> - **Elasticsearch** - 로그 저장 및 검색 엔진
> - **Kibana** - 로그 시각화 및 대시보드

- **메트릭** : 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고, 시스템의 현재 상태를 손쉽게 파악할 수도 있다. 메트릭 가운데 특히 유용한 것을 몇 가지 살펴보면 다음과 같다.
    - **호스트 단위 매트릭** : 개별 호스트의 상태 및 성능을 측정하기 위해 수집되는 매트릭으로, CPU, 메모리, 디스크 I/O 에 관한 메트릭이 여기 해당한다.
    - **종합(aggregated) 매트릭** : 시스템 안정성과 성능을 모니터링하기 위한 매트릭으로, 데이터베이스 계층의 성능, 캐시 계층의 성능같은 것이 여기 해당한다.
    - **핵심 비즈니스 메트릭** : 일별 능동 사용자(DAU, daily active user), 수익, 재방문율 같은 것이 여기 해당한다.
- **자동화** : 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 한다. 지속적 통합(Continuous Integration)이나 지속적 배포(Continuous deployment)를 자동화 도구를 이용해 수행한다.

## 이를 반영한 설계안

아래는 생산성을 위한 도구들과 메시지 큐를 적용하여 수정한 설계다. 

<img width="650" height="615" alt="image" src="https://github.com/user-attachments/assets/3840a13a-8437-437f-af81-8a523fc61be0" />


1. 메시지 큐는 각 컴포넌트가 보다 느슨히 결합(loosely coupled) 될 수 있도록 하고, 결함에 대한 내성을 높인다.
2. 로그, 모니터링, 매트릭, 자동화 등을 지원하기 위한 도구를 추가하였다.

# 데이터베이스의 규모 확장

저장할 데이터가 많아지면 데이터베이스에 대한 부하도 증가한다. 그때가 오면 데이터베이스를 증설할 방법을 찾아야 한다. 데이터베이스의 규모를 확장하는 데는 두 가지 접근법이 있다. 하나는 **수직적 규모 확장법**이고 다른 하나는 **수평적 규모 확장법**이다.

## 수직적 규모 확장법

기존 서버에 더 많은 , 또는 고성능의 자원 (CPU, RAM, 디스크 등 ) 을 중설하는 방법이다. 가령 아마존 AWS의 RDS(Relational Database Service)는 24TB RAM 을 갖춘 서버도 상품으로 제공하고 있다.

고성능 데이터베이스 서버는 많은 양의 데이터를 보관하고 처리할 수 있다. 예를 들어 스택오버플로우([stackoverflow.com](http://stackoverflow.com/))는 2013 년 한 해 동안 방문한 천만 명의 사용자 전부를 단 한 대의 마스터 데이터베이스로 처리하였다.

이러한 수직 규모 확장법의 한계도 알아보자.

1. 데이터베이스 서버 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수는 없다.
2. SPOF(Single Point of Failure) 로 인한 위험성이 크다.
3. 비용이 많이 든다. 고성능 서버로 갈수록 가격도 수직적으로 상승한다.

## 수평적 규모 확장법

데이터베이스의 수평적 확장은 샤딩(sharding)이라고도 부르는데, 더 많은 서버를 추가함으로써 성능을 향상시킬 수 있도록 한다.

샤딩은 대규모 데이터베이스를 샤드 (shard) 라고 부르는 작은 단위로 분할하는 기술을 일컫는다. **모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.**

아래 그림 1-21은 샤드로 분할된 데이터베이스의 예시이다. 사용자 데이터를 어느 샤드에 넣을 지는 사용자 ID 값에 따라 결정된다. 아래에서는 mod를 이용한 간단한 해시 함수로 샤드를 결정했다.

<img width="400" height="230" alt="image" src="https://github.com/user-attachments/assets/07c572e4-5c85-4b84-b941-246c325fefbd" />

<img width="650" height="540" alt="image" src="https://github.com/user-attachments/assets/0d753164-b6b4-48b2-8ade-4147a5b7060b" />


샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것은 **샤딩 키(sharding key)**를 어떻게 정하느냐 하는 것이다. 샤딩 키는 **파티션 키(partition key)**라고도 부르는데, **데이터가 어떻게 분산될지 정하는 하나 이상의 칼럼이다.**

위의 그림의 경우는 샤딩 키가 user_id가 된다. 적절한 샤딩 키를 통해 올바른 데이터베이스에 질의를 보내, 조회나 변경 처리를 효율적으로 할 수 있다. **적절한 샤딩 키란, 데이터를 고르게 분할 할 수 있는 샤딩 키이다.**

그러면 이제 샤딩을 도입함으로서  생기는 새로운 문제들에 대해 알아보자.

1. 데이터의 재 샤딩(resharding) 문제: 재 샤딩은 다음과 같은 경우에 필요하다. 
    1. 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때.
    2. 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다
    른 샤드에 비해 빨리 진행될 때. 분포의 불균등 문제는 샤딩 함수를 변경하거나 데이터를 재배치하여 해결할 수 있다.
    3. 유명인사(celebrity) 문제 : 핫스팟 키(hotspot key) 문제라고도 부르는데, **특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제다**.
    4. 조인과 정규화/비정규화: 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다.

아래의 그림 1-23 은 최종적으로 데이터베이스 샤딩까지 적용한 아키텍처다. 

<img width="630" height="620" alt="image" src="https://github.com/user-attachments/assets/9a7494da-be2a-423f-bc94-02974313eada" />



**시스템 규모 확장을 위해 이번 장에서 살펴본 기법들을 다시 한번 정리해 보면 다음과 같다.**

- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 한 많은 데이터를 캐시할 것
- 여러 데이터 센터를 지원할 것
- 정적 콘텐츠는 CDN 을 통해 서비스할 것
- 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분할할 것
- 시스템을 지속적으로 모니터링하고 , 자동화 도구들을 활용할 것
